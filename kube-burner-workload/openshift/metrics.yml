# API server

- query: irate(apiserver_request_total{verb="POST", resource="pods", subresource="binding",code="201"}[2m]) > 0
  metricName: schedulingThroughput

- query: histogram_quantile(0.99, sum(irate(apiserver_request_duration_seconds_bucket{apiserver="kube-apiserver", verb=~"LIST|GET", subresource!~"log|exec|portforward|attach|proxy"}[2m])) by (le, resource, verb, scope)) > 0
  metricName: readOnlyAPICallsLatency

- query: histogram_quantile(0.99, sum(irate(apiserver_request_duration_seconds_bucket{apiserver="kube-apiserver", verb=~"POST|PUT|DELETE|PATCH", subresource!~"log|exec|portforward|attach|proxy"}[2m])) by (le, resource, verb, scope)) > 0
  metricName: mutatingAPICallsLatency

- query: sum(irate(apiserver_request_total{apiserver="kube-apiserver",verb!="WATCH"}[2m])) by (verb,resource,code) > 0
  metricName: APIRequestRate

# Containers & pod metrics
- query: (sum(irate(container_cpu_usage_seconds_total{name!="",container!="POD",namespace=~"openshift-(etcd|oauth-apiserver|sdn|ovn-kubernetes|.*apiserver|authentication|.*controller-manager|.*scheduler|image-registry|operator-lifecycle-manager)"}[2m]) * 100) by (container, pod, namespace, node) and on (node) kube_node_role{role="master"}) > 0
  metricName: containerCPU-Masters

- query: (avg(irate(container_cpu_usage_seconds_total{name!="",container!="POD",namespace=~"openshift-(sdn|ovn-kubernetes|ingress)"}[2m]) * 100 and on (node) kube_node_role{role="worker"}) by (namespace, pod, container, node)) > 0
  metricName: containerCPU-AggregatedWorkers

- query: (sum(irate(container_cpu_usage_seconds_total{name!="",container!="POD",namespace=~"openshift-(monitoring|sdn|ovn-kubernetes|ingress)"}[2m]) * 100) by (container, pod, namespace, node) and on (node) kube_node_role{role="infra"}) > 0
  metricName: containerCPU-Infra

- query: (sum(container_memory_rss{name!="",container!="POD",namespace=~"openshift-(etcd|oauth-apiserver|.*apiserver|ovn-kubernetes|sdn|ingress|authentication|.*controller-manager|.*scheduler|image-registry|operator-lifecycle-manager)"}) by (container, pod, namespace, node) and on (node) kube_node_role{role="master"}) > 0
  metricName: containerMemory-Masters

- query: avg(container_memory_rss{name!="",container!="POD",namespace=~"openshift-(sdn|ovn-kubernetes|ingress)"} and on (node) kube_node_role{role="worker"}) by (pod, container, namespace, node)
  metricName: containerMemory-AggregatedWorkers

- query: (sum(container_memory_rss{name!="",container!="POD",namespace=~"openshift-(sdn|ovn-kubernetes|ingress|monitoring|image-registry)"}) by (container, pod, namespace, node) and on (node) kube_node_role{role="infra"}) > 0
  metricName: containerMemory-Infra

# Node metrics: CPU & Memory

- query: (sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")) > 0
  metricName: nodeCPU-Masters

- query: (avg((sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))) by (mode)) > 0
  metricName: nodeCPU-AggregatedWorkers

- query: (sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")) > 0
  metricName: nodeCPU-Infra

# We compute memory utilization by substrating available memory to the total

- query: avg((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryUtilization-AggregatedWorkers

- query: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeMemoryUtilization-Masters

- query: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")
  metricName: nodeMemoryUtilization-Infra

# Kubelet & CRI-O runtime metrics

- query: irate(process_cpu_seconds_total{service="kubelet",job="kubelet"}[2m]) * 100 and on (node) topk(3,avg_over_time(irate(process_cpu_seconds_total{service="kubelet",job="kubelet"}[2m])[{{ .elapsed }}:]) and on (node) kube_node_role{role="worker"})
  metricName: kubeletCPU

- query: process_resident_memory_bytes{service="kubelet",job="kubelet"} and on (node) topk(3,max_over_time(irate(process_resident_memory_bytes{service="kubelet",job="kubelet"}[2m])[{{ .elapsed }}:]) and on (node) kube_node_role{role="worker"})
  metricName: kubeletMemory

- query: irate(process_cpu_seconds_total{service="kubelet",job="crio"}[2m]) * 100 and on (node) topk(3,avg_over_time(irate(process_cpu_seconds_total{service="kubelet",job="crio"}[2m])[{{ .elapsed }}:]) and on (node) kube_node_role{role="worker"})
  metricName: crioCPU

- query: process_resident_memory_bytes{service="kubelet",job="crio"} and on (node) topk(3,max_over_time(irate(process_resident_memory_bytes{service="kubelet",job="crio"}[2m])[{{ .elapsed }}:]) and on (node) kube_node_role{role="worker"})
  metricName: crioMemory

# Etcd metrics

- query: sum(rate(etcd_server_leader_changes_seen_total[2m]))
  metricName: etcdLeaderChangesRate

- query: histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket[2m]))
  metricName: 99thEtcdDiskBackendCommitDurationSeconds

- query: histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket[2m]))
  metricName: 99thEtcdDiskWalFsyncDurationSeconds

- query: histogram_quantile(0.99, rate(etcd_network_peer_round_trip_time_seconds_bucket[5m]))
  metricName: 99thEtcdRoundTripTimeSeconds

- query: sum by (cluster_version)(etcd_cluster_version)
  metricName: etcdVersion
  instant: true

- query: cluster_version{type="completed"}
  metricName: clusterVersion
  instant: true

# Cluster metrics

- query: max_over_time( count(kube_pod_labels{label_kube_burner_job="network-policy-perf"})[{{ .elapsed }}:] )
  metricName: podCount

- query: max_over_time( count(kube_namespace_labels{label_kube_burner_job="network-policy-perf"})[{{ .elapsed }}:] )
  metricName: namespaceCount

- query: max_over_time( count(kube_networkpolicy_labels{networkpolicy=~"ingress.*"})[{{ .elapsed }}:] )
  metricName: netpolIngressCount

- query: max_over_time( count(kube_networkpolicy_labels{networkpolicy=~"egress.*"})[{{ .elapsed }}:] )
  metricName: netpolEgressCount

- query: kube_node_role
  metricName: nodeRoles

- query: sum(kube_node_status_condition{status="true"}) by (condition)
  metricName: nodeStatus

- query: kubernetes_build_info
  metricName: k8sVersion
  instant: true

# Prometheus metrics

- query: openshift:prometheus_tsdb_head_series:sum{job="prometheus-k8s"}
  metricName: prometheus-timeseriestotal

- query: openshift:prometheus_tsdb_head_samples_appended_total:sum{job="prometheus-k8s"}
  metricName: prometheus-ingestionrate

# OVS metrics
- query: (sum(irate(container_cpu_usage_seconds_total{id=~"/system.slice/ovs-vswitchd.service"}[2m]) * 100) by (node)) > 0
  metricName: ovsVswitchdCPU

- query: (sum(irate(container_cpu_usage_seconds_total{id=~"/system.slice/ovsdb-server.service"}[2m]) * 100) by (node)) > 0
  metricName: ovsdbServerCPU

- query: ovs_vswitchd_bridge_flows_total
  metricName: ovsFlowsCounter

- query: ovs_vswitchd_rconn_discarded
  metricName: ovsVswitchdRconnDiscarded

- query: ovs_vswitchd_rconn_overflow
  metricName: ovsVswitchdRconnOverflow

- query: ovs_vswitchd_stream_open
  metricName: ovsVswitchdStreamOpen

# OVN metrics
- query: ovn_controller_rconn_discarded
  metricName: ovnControllerRconnDiscarded

- query: ovn_controller_rconn_overflow
  metricName: ovnControllerRconnOverflow

- query: ovn_controller_flow_generation_95th_percentile
  metricName: ovnControllerFlowGeneration95Perc

- query: ovn_controller_flow_installation_95th_percentile
  metricName: ovnControllerFlowInstallation95Perc